{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2c60e18",
   "metadata": {},
   "source": [
    "### Create sample and load pre-token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a617a489",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = \"low low low low low lower lower widest widest widest newest newest newest newest newest newest\"\n",
    "\n",
    "freq_pre_token = {}\n",
    "for p in full_text.split(\" \"):\n",
    "    if p not in freq_pre_token: \n",
    "        freq_pre_token[p] = 1\n",
    "    else:\n",
    "        freq_pre_token[p] += 1\n",
    "\n",
    "freq_pre_token\n",
    "print(f\"Get key low: 'low': {freq_pre_token['low']}\")\n",
    "freq_pre_token = {tuple(k.encode('utf-8')): v for k, v in freq_pre_token.items()}\n",
    "\n",
    "print(f' low encode to: {[i for i in \"low\".encode(\"utf-8\")]}')\n",
    "print(f\"Get key low: 'low': {freq_pre_token[tuple('low'.encode('utf-8'))]}\")\n",
    "freq_pre_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c3c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vocab with 256 bytes values and <|endoftext|>\n",
    "index_2_vocab = {i: bytes([i]) for i in range(256)}\n",
    "index_2_vocab[256] = '<|endoftext|>'\n",
    "\n",
    "index_2_vocab[108] + index_2_vocab[111] + index_2_vocab[119]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332f4277",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_2_vocab[108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b195b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create linked list of each pre-token to tracking and update pair\n",
    "class Node:\n",
    "    def __init__(self, vocab_index, n_count=0):\n",
    "        self.vocab_index = vocab_index\n",
    "        self.next = None\n",
    "        self.prev = None\n",
    "        self.n_count = n_count\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(index_2_vocab[self.prev.vocab_index] if self.prev else None) + \"-\" + str(index_2_vocab[self.vocab_index]) + \"-\" + str(index_2_vocab[self.next.vocab_index] if self.next else None) + \" (\" + str(self.n_count) + \")\"\n",
    "\n",
    "\n",
    "freq_linked_list = {}\n",
    "\n",
    "for k, v in freq_pre_token.items():\n",
    "    nodes = tuple([Node(i, v) for i in k])\n",
    "    for pre, n in zip(nodes, nodes[1:]):\n",
    "        pre.next = n\n",
    "        n.prev = pre\n",
    "    freq_linked_list[nodes] = v\n",
    "\n",
    "\n",
    "freq_linked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b05a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "# init the pair_count\n",
    "\n",
    "# pair_count is a dict, with key is pair of bytes, and value is the list of pair node.\n",
    "# pair_version is a dict, with key is pair of bytes, and value is the version of the pair. Used to check out of date pair.\n",
    "# pair_max_heap is max heap of pair_count, \n",
    "\n",
    "pair_version = {}\n",
    "pair_count = {}\n",
    "max_heap = []\n",
    "\n",
    "for ns, v in freq_linked_list.items():\n",
    "    for n, next_n in zip(ns, ns[1:]):\n",
    "        pair_bytes = index_2_vocab[n.vocab_index] + index_2_vocab[next_n.vocab_index]\n",
    "        n_count = n.n_count\n",
    "\n",
    "        # update pair_count\n",
    "        if pair_bytes not in pair_count:\n",
    "            pair_count[pair_bytes] = {'n_count': n_count, 'pair_nodes': [(n, next_n)]}\n",
    "        else:\n",
    "            pair_count[pair_bytes]['n_count'] += n_count\n",
    "            pair_count[pair_bytes]['pair_nodes'].append((n, next_n))\n",
    "\n",
    "        # update pair version\n",
    "        if pair_bytes not in pair_version:\n",
    "            pair_version[pair_bytes] = 1\n",
    "        else:\n",
    "            pair_version[pair_bytes] += 1   \n",
    "\n",
    "        # update max_heap\n",
    "        heapq.heappush(max_heap, (-pair_count[pair_bytes]['n_count'], pair_bytes, pair_version[pair_bytes]))\n",
    "\n",
    "max_heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5db08a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max pair\n",
    "max_pair = heapq.heappop(max_heap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7197572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge max pair -> update pair_count -> update max_heap -> update pair_version\n",
    "max_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
